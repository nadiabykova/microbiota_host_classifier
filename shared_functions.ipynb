{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skbio.stats.composition import clr\n",
    "from skbio.stats.composition import multiplicative_replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read OTU tables and chao\n",
    "def read_data(path,skip_rows,filter_features=False):\n",
    "    r = pd.read_csv(path+'/hitdb_94/alpha_rar/chao1.txt',index_col='Unnamed: 0',sep='\\t')\n",
    "    r_mean = r.mean(axis=1)\n",
    "    r_mean = pd.DataFrame(r_mean,columns=['mean_chao']).transpose()\n",
    "    l = pd.read_csv(path+'/hitdb_94/OTUs/summarized_taxa/otu_table_L6.txt',index_col='#OTU ID',skiprows=skip_rows,sep='\\t')\n",
    "    l = l.div(l.sum(axis=0),axis=1)\n",
    "    rl = pd.concat([r_mean,l])\n",
    "    return(rl.transpose())\n",
    "def read_data_set(paths,skip_rows):\n",
    "    df = pd.DataFrame()\n",
    "    for p,p_name in paths:\n",
    "        try:\n",
    "            df = pd.concat([df,read_data(p,skip_rows).assign(project_name=p_name)],sort=False)\n",
    "        except:\n",
    "            print('Unable to load project:', p_name)\n",
    "    df.fillna(0,inplace=True)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling fuctions\n",
    "def sample_equal_categories_with_replacements(df,n,category_column,categories_list=None,random_state=None):\n",
    "    if (categories_list==None):\n",
    "        categories_list = pd.unique(df[category_column])\n",
    "    res = pd.DataFrame()\n",
    "    i = 0\n",
    "    for cat in categories_list:\n",
    "        avg_size = int((n-len(res))/(len(categories_list)-i))\n",
    "        #print(i,cat,avg_size)\n",
    "        res = pd.concat([res,df[df[category_column]==cat].sample(avg_size,replace=True,random_state = random_state)])\n",
    "        i = i + 1\n",
    "    #print('Final sample size:',len(res))\n",
    "    return(res)\n",
    "\n",
    "def sample_equal_categories_iterative(df,n,category_column,categories_list=None,random_state=None):\n",
    "    if (categories_list==None):\n",
    "        categories_list = df.groupby(category_column).size().sort_values().index\n",
    "    res = pd.DataFrame()\n",
    "    i = 0\n",
    "    for cat in categories_list:\n",
    "        avg_size = int((n-len(res))/(len(categories_list)-i))\n",
    "        sample_df = df[df[category_column]==cat]\n",
    "        sample_size = min(avg_size,len(sample_df))\n",
    "        #print(i,cat,avg_size)\n",
    "        res = pd.concat([res,sample_df.sample(sample_size,random_state = random_state)])\n",
    "        i = i + 1\n",
    "    #print('Final sample size:',len(res))\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names\n",
    "level_names = {0:'Kingdom',1:'Phylum',2:'Class',3:'Order',4:'Family',5:'Genus'}\n",
    "def view_name(level,features,clr_b):\n",
    "    l = level_names[level]\n",
    "    f,c = 'ALL',''\n",
    "    if (features=='best_holm'): f = 'MW-Holm'\n",
    "    if (features=='best_fdr'): f = 'MW-FDR'\n",
    "    if (clr_b): c = '_CLR'\n",
    "    return(l+'_'+f+c)\n",
    "def make_name(level,features,clr_b,fit):\n",
    "    f,c,ft = 'all','F','empty'\n",
    "    if (features=='best_holm'): f = 'bh'\n",
    "    if (features=='best_fdr'): f = 'bf'\n",
    "    if (clr_b): c = 'T'\n",
    "    if (fit): ft = 'fit'\n",
    "    return('catsNdogs_model_'+str(level)+':'+f+':'+c+':'+ft+'.joblib')\n",
    "def decode_name(name):\n",
    "    x = name.split('_')[-1].split('.')[0].split(':')\n",
    "    level = int(x[0])\n",
    "    features = 'all'\n",
    "    if (x[1]=='bh'): features = 'best_holm'\n",
    "    if (x[1]=='bf'): features = 'best_fdr'\n",
    "    clr_b = False\n",
    "    if (x[2]=='T'): clr_b = True\n",
    "    fit = False\n",
    "    if (x[3]=='fit'): fit = True\n",
    "    return(level,features,clr_b,fit)\n",
    "def get_tax_name_by_level(i):\n",
    "    return(level_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group by phylums\n",
    "def gp(x,level):\n",
    "    res_final = ''\n",
    "    for i in range(level,-1,-1):\n",
    "        res = x.split(';')[i]\n",
    "        res_final = res +';'+res_final\n",
    "    return(res_final[:-1])\n",
    "def get_phylums(df,level):\n",
    "    data_phylums = df.transpose()\n",
    "    data_phylums.index.name = 'index'\n",
    "    data_phylums = data_phylums.reset_index()\n",
    "    data_phylums['phylum'] = data_phylums['index'].apply(gp,args=[level])\n",
    "    data_phylums = data_phylums.drop('index',axis=1).groupby('phylum').agg('sum').transpose()\n",
    "    return(data_phylums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data transformation\n",
    "host_type_dtype = pd.api.types.CategoricalDtype(categories=['pet','human'], ordered=True)\n",
    "host_dtype = pd.api.types.CategoricalDtype(categories=['Canis familiaris','Felis catus','Homo sapiens'], ordered=True)\n",
    "my_dtype = {'Host_type':host_type_dtype,'Host':host_dtype}\n",
    "class transformer:\n",
    "    def __init__(self,bf,chao=True,level=5,clr_b=False):\n",
    "        self.bf=bf\n",
    "        self.add_chao=chao\n",
    "        self.level=level\n",
    "        self.clr_b=clr_b        \n",
    "    def transform_df(self,taxa_df,chao_df):\n",
    "        X_df = get_phylums(taxa_df,self.level)\n",
    "        features_union = set(X_df.columns).union(set(self.bf))\n",
    "        X_df = X_df.reindex(columns=features_union).fillna(0)\n",
    "        if (self.clr_b):\n",
    "            X_clr = clr(multiplicative_replacement(np.array(X_df)))\n",
    "            X_df = pd.DataFrame(X_clr,columns = X_df.columns,index = X_df.index)\n",
    "        X_df = X_df.reindex(columns=self.bf)\n",
    "        if (self.add_chao):\n",
    "            X_df['mean_chao'] = chao_df\n",
    "        X = np.array(X_df)\n",
    "        return(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "#bf = joblib.load('joblib/catsNdogs_mw_bf.joblib')\n",
    "#data = joblib.load('joblib/catsNdogs_data.joblib')\n",
    "#dataset_info = joblib.load('joblib/catsNdogs_dataset_info.joblib')\n",
    "#taxa_df,chao_df,y = data.get_data_from_ind(dataset_info.index,False)\n",
    "##display(taxa_df)\n",
    "##display(chao_df)\n",
    "#f,chao = bf[(5,'all')]\n",
    "##print(f)\n",
    "##print(chao)\n",
    "#tf = transformer(bf=f,chao=chao,level=5,clr_b=True)\n",
    "#X = tf.transform_df(taxa_df,chao_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mydata:\n",
    "    def __init__(self,taxa_df,chao_df,info_df,y_col='Host_type'):\n",
    "        self.taxa = taxa_df.copy()\n",
    "        self.taxa.fillna(0,inplace=True)\n",
    "        self.taxa = self.taxa.div(self.taxa.sum(axis=1),axis=0)\n",
    "        self.chao = chao_df.copy()\n",
    "        self.info = info_df.copy()\n",
    "        self.y_col = y_col\n",
    "        self.filtered_features = {}\n",
    "    def set_filtered_taxa(self,data_f,level):\n",
    "        self.filtered_features[level] = data_f\n",
    "    \n",
    "    def get_taxa(self,level,filtered):\n",
    "        res = get_phylums(self.taxa,level)\n",
    "        if (filtered):\n",
    "            return(res.reindex(columns = self.filtered_features[level]))\n",
    "        else:\n",
    "            return(res)\n",
    "        \n",
    "    def get_taxa_from_ind(self,ind,level,filtered):\n",
    "        res = self.get_taxa(level,filtered)\n",
    "        return(res.loc[ind,:])\n",
    "  \n",
    "    def get_data_from_ind(self,ind,level,filtered):\n",
    "        y = np.array(self.info.loc[ind,self.y_col].astype(my_dtype[self.y_col]).cat.codes)\n",
    "        return(self.get_taxa_from_ind(ind,level,filtered),self.chao.loc[ind],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def projects_table(data):\n",
    "    x = data.groupby(['project_name','Host','Host_type']).size().sort_values(ascending=False).to_frame()\n",
    "    x.columns = ['Samples #']\n",
    "    x.sort_values(['Host','Samples #'],ascending=False,inplace=True)\n",
    "    return(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
