{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "import itertools\n",
    "import shared_functions\n",
    "\n",
    "from sklearn import model_selection, ensemble, metrics\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_path = 'data/projects_for_test'\n",
    "test_srr_info1 = 'data/projects_for_test/PMID32078625_metadata.csv'\n",
    "test_srr_info2 = 'data/projects_for_test/PRJNA493726_metadata.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = joblib.load('joblib/catsNdogs_mw_bf.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load cats and dogs test projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 286)\n",
      "PMID32078625    238\n",
      "PRJNA401442      56\n",
      "PRJNA589580      35\n",
      "PRJNA592436      29\n",
      "Name: project_name, dtype: int64\n",
      "PMID32078625_dog    192\n",
      "PRJNA401442_dog      56\n",
      "PMID32078625_cat     46\n",
      "PRJNA589580_dog      35\n",
      "PRJNA592436_dog      29\n",
      "Name: project_name2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "cd_test_projects = ['PRJNA592436_f1','PRJNA589580_f1','PRJNA401442','PMID32078625_f1']\n",
    "projects = [os.path.join(data_path, p) for p in cd_test_projects]\n",
    "#print(projects)\n",
    "projects_name = [ele.replace('_f1','') for ele in cd_test_projects]\n",
    "data = shared_functions.read_data_set(zip(projects, projects_name),1)\n",
    "data.index = [ele.replace('_1','') for ele in data.index]\n",
    "data.index = [ele.replace('_L001_R1_001','') for ele in data.index]\n",
    "data['Host_type'] = 'catNdog'\n",
    "z = pd.read_csv(test_srr_info1,sep=';')\n",
    "#display(z.head())\n",
    "z.set_index('sample_name',inplace=True)\n",
    "dz = data.merge(z,how='left',left_index=True,right_index=True)\n",
    "dz['DESCRIPTION'] = dz.DESCRIPTION.apply(str)\n",
    "dz['Host'] = dz.apply(lambda x: 'Canis familiaris' if (x.DESCRIPTION=='nan') \n",
    "                      else ('Canis familiaris' if (x.DESCRIPTION=='Dog feces')\n",
    "                            else 'Felis catus'),axis=1)\n",
    "dz.project_name.value_counts()\n",
    "dz.drop('DESCRIPTION',axis=1,inplace=True)\n",
    "dz['project_name2'] = dz.apply(lambda x: x.project_name+'_dog' if (x.Host=='Canis familiaris')\n",
    "                              else x.project_name+'_cat',axis=1)\n",
    "print(dz.shape)\n",
    "print(dz.project_name.value_counts())\n",
    "print(dz.project_name2.value_counts())\n",
    "cd_test_data = dz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load human test projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(358, 279)\n",
      "PRJNA385551    284\n",
      "PRJNA493726     74\n",
      "Name: project_name, dtype: int64\n",
      "PRJNA385551_HC     284\n",
      "PRJNA493726_SLE     37\n",
      "PRJNA493726_HC      19\n",
      "PRJNA493726_RA      18\n",
      "Name: project_name2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "human_test_projects = ['PRJNA385551_f1','PRJNA493726_f1']\n",
    "projects = [os.path.join(data_path, p) for p in human_test_projects]\n",
    "#print(projects)\n",
    "projects_name = [ele.replace('_f1','') for ele in human_test_projects]\n",
    "data = shared_functions.read_data_set(zip(projects, projects_name),1)\n",
    "data.index = [ele.replace('_1','') for ele in data.index]\n",
    "data['Host_type'] = 'human'\n",
    "data['Host'] = 'Homo sapiens'\n",
    "z = pd.read_csv(test_srr_info2,sep=',').loc[:,['Run','SampleName']]\n",
    "#.loc[:,['Run','SampleType']]\n",
    "z.set_index('Run',inplace=True)\n",
    "dz = data.merge(z,how='left',left_index=True,right_index=True)\n",
    "dz['SampleName'] = dz.SampleName.apply(str)\n",
    "dz['SampleName'] = dz.SampleName.apply(lambda x: x.split('.')[0])\n",
    "dz['health'] = dz.apply(lambda x: 'HC' if (x.SampleName=='nan') \n",
    "                        else x.SampleName,axis=1)\n",
    "dz['project_name2'] = dz.project_name+'_'+dz.health\n",
    "dz.drop(['SampleName','health'],axis=1,inplace=True)\n",
    "print(dz.shape)\n",
    "print(dz.project_name.value_counts())\n",
    "print(dz.project_name2.value_counts())\n",
    "human_test_data = dz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([cd_test_data,human_test_data])\n",
    "test_data = shared_functions.mydata(taxa_df = df.drop(['mean_chao','Host','Host_type','project_name','project_name2'],axis=1),\n",
    "                               chao_df = df['mean_chao'],\n",
    "                               info_df = df.loc[:,['Host','Host_type','project_name','project_name2']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models accuracy on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_each_project(pr_col):\n",
    "    levels = [5]\n",
    "    features = ['all','best_holm','best_fdr']\n",
    "    clr_b = [False,True]\n",
    "    res_list = []\n",
    "    for level,features,clr_b in itertools.product(levels, features, clr_b):\n",
    "        view_name = shared_functions.view_name(level,features,clr_b)\n",
    "        print(view_name)\n",
    "        filename = shared_functions.make_name(level,features,clr_b,True)\n",
    "        rf = joblib.load('joblib/'+filename)\n",
    "        f,chao = bf[(level,features)]\n",
    "        tf = shared_functions.transformer(bf=f,chao=chao,level=level,clr_b=clr_b)\n",
    "        ti = test_data.info\n",
    "        tps = pd.unique(ti[pr_col])\n",
    "        for tp in tps:\n",
    "            dt = ti[ti[pr_col]==tp]\n",
    "            ht = pd.unique(dt.Host_type)[0]\n",
    "            taxa_df,chao_df,y = test_data.get_data_from_ind(dt.index,False)\n",
    "            X = tf.transform_df(taxa_df,chao_df)\n",
    "            y_predict = rf.predict(X)\n",
    "            acc = metrics.accuracy_score(y,y_predict)\n",
    "            acc_str = '%.3f' % acc\n",
    "            res_d = {'model_name':view_name,'test_project':tp,'Host_type':ht,'accuracy':acc_str}\n",
    "            res_list.append(res_d)\n",
    "    return(pd.DataFrame(res_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genus_ALL\n",
      "Genus_ALL_CLR\n",
      "Genus_MW-Holm\n",
      "Genus_MW-Holm_CLR\n",
      "Genus_MW-FDR\n",
      "Genus_MW-FDR_CLR\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Host_type</th>\n",
       "      <th>model_name</th>\n",
       "      <th colspan=\"5\" halign=\"left\">catNdog</th>\n",
       "      <th colspan=\"4\" halign=\"left\">human</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test_project</th>\n",
       "      <th></th>\n",
       "      <th>PMID32078625_cat</th>\n",
       "      <th>PMID32078625_dog</th>\n",
       "      <th>PRJNA401442_dog</th>\n",
       "      <th>PRJNA589580_dog</th>\n",
       "      <th>PRJNA592436_dog</th>\n",
       "      <th>PRJNA385551_HC</th>\n",
       "      <th>PRJNA493726_HC</th>\n",
       "      <th>PRJNA493726_RA</th>\n",
       "      <th>PRJNA493726_SLE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Genus_ALL</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Genus_ALL_CLR</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.979</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Genus_MW-FDR</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.948</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Genus_MW-FDR_CLR</td>\n",
       "      <td>0.935</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.944</td>\n",
       "      <td>0.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Genus_MW-Holm</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.995</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.993</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Genus_MW-Holm_CLR</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.984</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.993</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.730</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Host_type            model_name          catNdog                   \\\n",
       "test_project                    PMID32078625_cat PMID32078625_dog   \n",
       "0                     Genus_ALL            0.870            0.984   \n",
       "1                 Genus_ALL_CLR            0.913            0.979   \n",
       "2                  Genus_MW-FDR            0.870            0.948   \n",
       "3              Genus_MW-FDR_CLR            0.935            0.995   \n",
       "4                 Genus_MW-Holm            1.000            0.995   \n",
       "5             Genus_MW-Holm_CLR            0.978            0.984   \n",
       "\n",
       "Host_type                                                             human  \\\n",
       "test_project PRJNA401442_dog PRJNA589580_dog PRJNA592436_dog PRJNA385551_HC   \n",
       "0                      1.000           1.000           1.000          1.000   \n",
       "1                      1.000           1.000           1.000          1.000   \n",
       "2                      1.000           1.000           1.000          1.000   \n",
       "3                      1.000           1.000           1.000          1.000   \n",
       "4                      1.000           1.000           1.000          0.993   \n",
       "5                      1.000           1.000           1.000          0.993   \n",
       "\n",
       "Host_type                                                   \n",
       "test_project PRJNA493726_HC PRJNA493726_RA PRJNA493726_SLE  \n",
       "0                     1.000          1.000           0.919  \n",
       "1                     1.000          1.000           0.865  \n",
       "2                     1.000          0.889           0.784  \n",
       "3                     1.000          0.944           0.838  \n",
       "4                     1.000          0.889           0.703  \n",
       "5                     0.842          0.889           0.730  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res = test_each_project('project_name2')\n",
    "t_acc = res.pivot_table(index=['model_name'], columns=['Host_type','test_project'],values='accuracy',aggfunc='first').reset_index()\n",
    "display(t_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_acc.to_csv('results/catsNdogs_Table5_1.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models accuracy on a mixed class sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ti = test_data.info\n",
    "cd = ti[ti.Host_type=='catNdog']\n",
    "humans = ti[(ti.Host_type=='human')]\n",
    "HC_humans = humans[~humans.project_name2.isin(['PRJNA493726_SLE','PRJNA493726_RA'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_on_sample(human_df,tf,rf):\n",
    "    results_list = []\n",
    "    for i in range(100):\n",
    "        cd_p = shared_functions.sample_equal_categories_with_replacements(\n",
    "            cd,200,'project_name2',None,i)\n",
    "        hum_p = shared_functions.sample_equal_categories_with_replacements(\n",
    "            human_df,200,'project_name2',None,i)\n",
    "        test_i = pd.concat([cd_p,hum_p])\n",
    "        taxa_df,chao_df,y = test_data.get_data_from_ind(test_i.index,False)\n",
    "        X = tf.transform_df(taxa_df,chao_df)\n",
    "        y_predict = rf.predict(X)\n",
    "        acc = metrics.accuracy_score(y,y_predict)\n",
    "        pr = metrics.precision_score(y,y_predict)\n",
    "        recall = metrics.recall_score(y,y_predict)\n",
    "        f1 = metrics.f1_score(y,y_predict)\n",
    "        rd = {'acc':acc,'precision':pr,'recall':recall,'f1':f1}\n",
    "        results_list.append(rd)\n",
    "    x = pd.DataFrame(results_list)\n",
    "    m = x.mean()\n",
    "    st = x.std()\n",
    "    res = pd.DataFrame.from_dict({'m':m,'s':st})\n",
    "    res['mean_std'] = res.apply(lambda x: ('%.3f ± %.3f' % (x.m, x.s)),axis=1)\n",
    "    res.drop(['m','s'],axis=1,inplace=True)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">Genus_ALL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Genus_ALL_CLR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Genus_MW-FDR</th>\n",
       "      <th colspan=\"2\" halign=\"left\">Genus_MW-FDR_CLR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>total dataset</th>\n",
       "      <th>healthy people dataset</th>\n",
       "      <th>total dataset</th>\n",
       "      <th>healthy people dataset</th>\n",
       "      <th>total dataset</th>\n",
       "      <th>healthy people dataset</th>\n",
       "      <th>total dataset</th>\n",
       "      <th>healthy people dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>acc</td>\n",
       "      <td>0.976 ± 0.008</td>\n",
       "      <td>0.986 ± 0.006</td>\n",
       "      <td>0.973 ± 0.010</td>\n",
       "      <td>0.990 ± 0.006</td>\n",
       "      <td>0.942 ± 0.011</td>\n",
       "      <td>0.982 ± 0.006</td>\n",
       "      <td>0.965 ± 0.009</td>\n",
       "      <td>0.993 ± 0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>precision</td>\n",
       "      <td>0.972 ± 0.012</td>\n",
       "      <td>0.972 ± 0.012</td>\n",
       "      <td>0.980 ± 0.011</td>\n",
       "      <td>0.981 ± 0.011</td>\n",
       "      <td>0.963 ± 0.013</td>\n",
       "      <td>0.966 ± 0.012</td>\n",
       "      <td>0.985 ± 0.010</td>\n",
       "      <td>0.986 ± 0.009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>recall</td>\n",
       "      <td>0.980 ± 0.010</td>\n",
       "      <td>1.000 ± 0.000</td>\n",
       "      <td>0.966 ± 0.013</td>\n",
       "      <td>1.000 ± 0.000</td>\n",
       "      <td>0.919 ± 0.017</td>\n",
       "      <td>1.000 ± 0.000</td>\n",
       "      <td>0.945 ± 0.014</td>\n",
       "      <td>1.000 ± 0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f1</td>\n",
       "      <td>0.976 ± 0.008</td>\n",
       "      <td>0.986 ± 0.006</td>\n",
       "      <td>0.973 ± 0.010</td>\n",
       "      <td>0.990 ± 0.006</td>\n",
       "      <td>0.940 ± 0.011</td>\n",
       "      <td>0.982 ± 0.006</td>\n",
       "      <td>0.965 ± 0.009</td>\n",
       "      <td>0.993 ± 0.005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Genus_ALL                         Genus_ALL_CLR  \\\n",
       "           total dataset healthy people dataset  total dataset   \n",
       "acc        0.976 ± 0.008          0.986 ± 0.006  0.973 ± 0.010   \n",
       "precision  0.972 ± 0.012          0.972 ± 0.012  0.980 ± 0.011   \n",
       "recall     0.980 ± 0.010          1.000 ± 0.000  0.966 ± 0.013   \n",
       "f1         0.976 ± 0.008          0.986 ± 0.006  0.973 ± 0.010   \n",
       "\n",
       "                                   Genus_MW-FDR                         \\\n",
       "          healthy people dataset  total dataset healthy people dataset   \n",
       "acc                0.990 ± 0.006  0.942 ± 0.011          0.982 ± 0.006   \n",
       "precision          0.981 ± 0.011  0.963 ± 0.013          0.966 ± 0.012   \n",
       "recall             1.000 ± 0.000  0.919 ± 0.017          1.000 ± 0.000   \n",
       "f1                 0.990 ± 0.006  0.940 ± 0.011          0.982 ± 0.006   \n",
       "\n",
       "          Genus_MW-FDR_CLR                         \n",
       "             total dataset healthy people dataset  \n",
       "acc          0.965 ± 0.009          0.993 ± 0.005  \n",
       "precision    0.985 ± 0.010          0.986 ± 0.009  \n",
       "recall       0.945 ± 0.014          1.000 ± 0.000  \n",
       "f1           0.965 ± 0.009          0.993 ± 0.005  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "levels = [5]\n",
    "features = ['all','best_fdr']\n",
    "clr_b = [False,True]\n",
    "res_list = []\n",
    "pieces2 = {}\n",
    "for level,features,clr_b in itertools.product(levels, features, clr_b):\n",
    "    filename = shared_functions.make_name(level,features,clr_b,True)\n",
    "    view_name = shared_functions.view_name(level,features,clr_b)\n",
    "    rf = joblib.load('joblib/'+filename)\n",
    "    f,chao = bf[(level,features)]\n",
    "    tf = shared_functions.transformer(bf=f,chao=chao,level=level,clr_b=clr_b)\n",
    "    all_res = test_on_sample(humans,tf,rf)\n",
    "    healthy_res = test_on_sample(HC_humans,tf,rf)\n",
    "    pieces = {'total dataset' : all_res,\n",
    "              'healthy people dataset' :healthy_res}\n",
    "    t5 = pd.concat(pieces, axis=1)\n",
    "    t5.columns = t5.columns.droplevel(1)\n",
    "    pieces2[view_name] = t5\n",
    "t5_all = pd.concat(pieces2, axis=1)\n",
    "t5_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5_all.to_csv('results/catsNdogs_Table5_2.txt',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_on_sample_2(human_df):\n",
    "#     results_list = []\n",
    "#     for i in range(100):\n",
    "#         cd_cats = shared_functions.sample_equal_categories_with_replacements(\n",
    "#             cd_test_data,200,'project_name2',None,i)\n",
    "#         hum_p = shared_functions.sample_equal_categories_with_replacements(\n",
    "#             human_df,200,'project_name2',None,i)\n",
    "#         #print(cd_p.project_name.value_counts())\n",
    "#         #print(hum_p.project_name.value_counts())\n",
    "#         test_data = pd.concat([cd_p,hum_p])\n",
    "#         test_data.drop('project_name2',axis=1,inplace=True)\n",
    "#         X,y = tf.transform_df(df=test_data)\n",
    "#         y_predict = rf.predict(X)\n",
    "#         acc = metrics.accuracy_score(y,y_predict)\n",
    "#         pr = metrics.precision_score(y,y_predict)\n",
    "#         recall = metrics.recall_score(y,y_predict)\n",
    "#         f1 = metrics.f1_score(y,y_predict)\n",
    "#         rd = {'acc':acc,'precision':pr,'recall':recall,'f1':f1}\n",
    "#         results_list.append(rd)\n",
    "#     x = pd.DataFrame(results_list)\n",
    "#     m = x.mean()\n",
    "#     st = x.std()\n",
    "#     res = pd.DataFrame.from_dict({'mean':m,'std':st})\n",
    "#     return(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
